{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82bc1def-93eb-427e-9642-8553963444c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Change just here the sequence length that you want "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7597003-1c4f-4c81-9491-77ba911c6677",
   "metadata": {},
   "source": [
    "Ctrl+f \"path_to_change\" to adjust the paths and make the code work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1c7830a-33f8-4ab2-8abd-56ce81c513db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_13740/4118683251.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['centred_sequence'] = df_filtered.apply(get_centered_sequence, axis=1)\n",
      "/var/tmp/ipykernel_13740/4118683251.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['centred_sequence_'] = df_filtered.apply(lambda row: reverse_complement(row['centred_sequence'].upper()) if row['strand'] == '-' else row['centred_sequence'], axis=1)\n",
      "/var/tmp/ipykernel_13740/4118683251.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered.drop(columns = [\"centred_sequence\"], inplace = True)\n",
      "/var/tmp/ipykernel_13740/4118683251.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered.rename(columns = {\"centred_sequence_\" : \"centred_sequence\"}, inplace = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>centred_sequence</th>\n",
       "      <th>Pituitary</th>\n",
       "      <th>last_gene_id</th>\n",
       "      <th>GENE_ID</th>\n",
       "      <th>dex_gene_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TGACTTGCTGTCTCTAGATAGTTGCTGCAAGTCTAAAAAAACTTGA...</td>\n",
       "      <td>0.849062</td>\n",
       "      <td>ENSG00000118473.23</td>\n",
       "      <td>ENSG00000118473</td>\n",
       "      <td>ENSG00000118473.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCTTTGAGCTCCAGACCCAAGTGTCTGGTGGCCTAGAGGCTGCGAA...</td>\n",
       "      <td>1.273982</td>\n",
       "      <td>ENSG00000162426.16</td>\n",
       "      <td>ENSG00000162426</td>\n",
       "      <td>ENSG00000162426.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAGCAGTTTCACTCCTATGTATACACTCAAGAAAATGGAAAACAGG...</td>\n",
       "      <td>1.500136</td>\n",
       "      <td>ENSG00000157191.20</td>\n",
       "      <td>ENSG00000157191</td>\n",
       "      <td>ENSG00000157191.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATGGTTCAAGCCCCCATCTAAGGGGAGCCTCCTGGAATTTATTTAT...</td>\n",
       "      <td>1.298134</td>\n",
       "      <td>ENSG00000169504.15</td>\n",
       "      <td>ENSG00000169504</td>\n",
       "      <td>ENSG00000169504.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACTCCTATGCATAGAAAACAAGATGGTTCCAGGCAGAAGGGCCCAG...</td>\n",
       "      <td>0.825821</td>\n",
       "      <td>ENSG00000142920.18</td>\n",
       "      <td>ENSG00000142920</td>\n",
       "      <td>ENSG00000142920.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21861</th>\n",
       "      <td>GAAAAATACTGTAATTGGCATAAAATATAAATTGTGATGGGACACC...</td>\n",
       "      <td>1.946064</td>\n",
       "      <td>ENSG00000008735.14</td>\n",
       "      <td>ENSG00000008735</td>\n",
       "      <td>ENSG00000008735.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21862</th>\n",
       "      <td>GTTCAGGGACCCACAGCAAAGTCTGTCTAACTAGACGCATCCGATC...</td>\n",
       "      <td>1.810176</td>\n",
       "      <td>ENSG00000100299.18</td>\n",
       "      <td>ENSG00000100299</td>\n",
       "      <td>ENSG00000100299.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21863</th>\n",
       "      <td>CTGCCTTCTGGGTTCAAATGATTCTCCTGCCTCAGCTTTCTGAGTA...</td>\n",
       "      <td>0.013292</td>\n",
       "      <td>ENSG00000100312.11</td>\n",
       "      <td>ENSG00000100312</td>\n",
       "      <td>ENSG00000100312.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21864</th>\n",
       "      <td>ACATAAAAATGTTTTATAGATTGGACTAAAGACCTTTGAGGTCTCT...</td>\n",
       "      <td>1.421082</td>\n",
       "      <td>ENSG00000079974.19</td>\n",
       "      <td>ENSG00000079974</td>\n",
       "      <td>ENSG00000079974.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21865</th>\n",
       "      <td>AATATTATATATAATATTATATATTATATTTAATATAATATTATAT...</td>\n",
       "      <td>-2.254757</td>\n",
       "      <td>ENSG00000206142.9</td>\n",
       "      <td>ENSG00000206142</td>\n",
       "      <td>ENSG00000206142.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21866 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        centred_sequence  Pituitary  \\\n",
       "0      TGACTTGCTGTCTCTAGATAGTTGCTGCAAGTCTAAAAAAACTTGA...   0.849062   \n",
       "1      TCTTTGAGCTCCAGACCCAAGTGTCTGGTGGCCTAGAGGCTGCGAA...   1.273982   \n",
       "2      CAGCAGTTTCACTCCTATGTATACACTCAAGAAAATGGAAAACAGG...   1.500136   \n",
       "3      ATGGTTCAAGCCCCCATCTAAGGGGAGCCTCCTGGAATTTATTTAT...   1.298134   \n",
       "4      ACTCCTATGCATAGAAAACAAGATGGTTCCAGGCAGAAGGGCCCAG...   0.825821   \n",
       "...                                                  ...        ...   \n",
       "21861  GAAAAATACTGTAATTGGCATAAAATATAAATTGTGATGGGACACC...   1.946064   \n",
       "21862  GTTCAGGGACCCACAGCAAAGTCTGTCTAACTAGACGCATCCGATC...   1.810176   \n",
       "21863  CTGCCTTCTGGGTTCAAATGATTCTCCTGCCTCAGCTTTCTGAGTA...   0.013292   \n",
       "21864  ACATAAAAATGTTTTATAGATTGGACTAAAGACCTTTGAGGTCTCT...   1.421082   \n",
       "21865  AATATTATATATAATATTATATATTATATTTAATATAATATTATAT...  -2.254757   \n",
       "\n",
       "             last_gene_id          GENE_ID         dex_gene_id  \n",
       "0      ENSG00000118473.23  ENSG00000118473  ENSG00000118473.17  \n",
       "1      ENSG00000162426.16  ENSG00000162426  ENSG00000162426.10  \n",
       "2      ENSG00000157191.20  ENSG00000157191  ENSG00000157191.15  \n",
       "3      ENSG00000169504.15  ENSG00000169504  ENSG00000169504.10  \n",
       "4      ENSG00000142920.18  ENSG00000142920  ENSG00000142920.12  \n",
       "...                   ...              ...                 ...  \n",
       "21861  ENSG00000008735.14  ENSG00000008735  ENSG00000008735.10  \n",
       "21862  ENSG00000100299.18  ENSG00000100299  ENSG00000100299.13  \n",
       "21863  ENSG00000100312.11  ENSG00000100312   ENSG00000100312.6  \n",
       "21864  ENSG00000079974.19  ENSG00000079974  ENSG00000079974.13  \n",
       "21865   ENSG00000206142.9  ENSG00000206142   ENSG00000206142.5  \n",
       "\n",
       "[21866 rows x 5 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length_left = 2000\n",
    "sequence_length_right = 2000\n",
    "\n",
    "\n",
    "# Les deux listes\n",
    "liste_nc = [\n",
    "    'NC_000001.11', 'NC_000002.12', 'NC_000003.12', 'NC_000004.12', 'NC_000005.10',\n",
    "    'NC_000006.12', 'NC_000007.14', 'NC_000008.11', 'NC_000009.12',\n",
    "    'NC_000010.11', 'NC_000011.10', 'NC_000012.12', 'NC_000013.11',\n",
    "    'NC_000014.9', 'NC_000015.10', 'NC_000016.10', 'NC_000017.11',\n",
    "    'NC_000018.10', 'NC_000019.10', 'NC_000020.11', 'NC_000021.9',\n",
    "    'NC_000022.11', 'NC_000023.11', 'NC_000024.10'\n",
    "]\n",
    "\n",
    "liste_chr = [\n",
    "    'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8',\n",
    "    'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16',\n",
    "    'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX',\n",
    "    'chrY'\n",
    "]\n",
    "\n",
    "# Création du dictionnaire dans l'ordre demandé\n",
    "dex_to_ncbi = dict(zip(liste_chr, liste_nc))\n",
    "\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "\n",
    "# Charger le fichier FASTA et stocker les séquences dans un dictionnaire\n",
    "fasta_file = \"../ncbi_dataset/data/GCF_000001405.40/GCF_000001405.40_GRCh38.p14_genomic.fna\" #path_to_change genome_code\n",
    "chromosome_sequences = {}\n",
    "for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "    chromosome_sequences[record.id] = str(record.seq)\n",
    "\n",
    "# Charger le DataFrame\n",
    "df = pd.read_csv(\"dex_annotations_important.csv\") #path_to_change the annotations file\n",
    "df_filtered = df[df['seqname'] != 'chrM']\n",
    "\n",
    "\n",
    "# Fonction pour extraire la séquence centrée autour de 'start' ou 'end' basé sur 'strand'\n",
    "def get_centered_sequence(row):\n",
    "    chromosome = dex_to_ncbi[row['seqname']]\n",
    "    if row['strand'] == '+':\n",
    "        center = row['start']\n",
    "    else:\n",
    "        center = row['end']\n",
    "    \n",
    "    seq = chromosome_sequences.get(chromosome, \"\")\n",
    "    if seq:\n",
    "        start_idx = max(0, center - sequence_length_left)\n",
    "        end_idx = min(len(seq), center + sequence_length_right)\n",
    "        return seq[start_idx-1:end_idx]\n",
    "    return \"\"\n",
    "\n",
    "# Ajouter la nouvelle colonne avec les séquences extraites\n",
    "df_filtered['centred_sequence'] = df_filtered.apply(get_centered_sequence, axis=1)\n",
    "\n",
    "def reverse_complement(sequence):\n",
    "    # Dictionnaire de complémentarité des nucléotides\n",
    "    complement = {'A': 'T', 'T': 'A', 'C': 'G', 'G': 'C',\n",
    "                  'a': 't', 't': 'a', 'c': 'g', 'g': 'c',\n",
    "                  'N': 'N', 'n': 'n'}  # 'N' reste 'N', 'n' reste 'n'\n",
    "    \n",
    "    # Générer la séquence complémentaire\n",
    "    complement_sequence = ''.join(complement.get(base, base) for base in sequence)\n",
    "    \n",
    "    # Inverser la séquence complémentaire\n",
    "    reverse_complement_sequence = complement_sequence[::-1]\n",
    "    \n",
    "    return reverse_complement_sequence\n",
    "\n",
    "df_filtered['centred_sequence_'] = df_filtered.apply(lambda row: reverse_complement(row['centred_sequence'].upper()) if row['strand'] == '-' else row['centred_sequence'], axis=1)\n",
    "df_filtered.drop(columns = [\"centred_sequence\"], inplace = True)\n",
    "df_filtered.rename(columns = {\"centred_sequence_\" : \"centred_sequence\"}, inplace = True)\n",
    "\n",
    "pituitary = pd.read_csv(\"final_result.csv\") # path_to_change gene_expression data from gtex \n",
    "\n",
    "final_df = pd.merge(df_filtered, pituitary, left_on=\"GENE_ID\", right_on='gene_id')\n",
    "\n",
    "# Replace zeros with a small value to avoid errors in log transformation\n",
    "final_df['Pituitary'] = final_df['Pituitary'].replace(0, 0.001)\n",
    "\n",
    "# Take the logarithm base 10 of the 'Pituitary' column\n",
    "final_df['Pituitary'] = np.log10(final_df['Pituitary'])\n",
    "\n",
    "# Select desired columns\n",
    "final_df = final_df[['centred_sequence', 'Pituitary', 'last_gene_id', 'GENE_ID', 'dex_gene_id']]\n",
    "\n",
    "# Convert 'centred_sequence' to uppercase\n",
    "final_df['centred_sequence'] = final_df['centred_sequence'].str.upper()\n",
    "\n",
    "final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8539dbb-3aaa-431e-86ed-9b7a911160ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def create_or_empty_directory(dir_path):\n",
    "    if os.path.exists(dir_path):\n",
    "        # If directory exists, delete all its contents\n",
    "        shutil.rmtree(dir_path)\n",
    "    # Create the directory (or recreate it if it was deleted)\n",
    "    os.makedirs(dir_path)\n",
    "\n",
    "\n",
    "if sequence_length_left > 0 and sequence_length_right > 0:\n",
    "    path_ = f\"DATASETS/GRCH38/{sequence_length_left}_tss_{sequence_length_right}\"\n",
    "elif sequence_length_left > 0:\n",
    "    path_ = f\"DATASETS/GRCH38/{sequence_length_left}_tss\"\n",
    "elif sequence_length_right > 0:\n",
    "    path_ = f\"DATASETS/GRCH38/tss_{sequence_length_right}\"\n",
    "else:\n",
    "    path_ = \"DATASETS/GRCH38/tss\"\n",
    "\n",
    "create_or_empty_directory(path_)\n",
    "\n",
    "final_df.to_csv(f\"{path_}/{path_.split('/')[-1]}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8503d924-e330-47a2-a8c1-1ef8a43bc07f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Format the dataset for DNABERT-2 method "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7682eb57-5cba-4d54-b346-b0c2e921d4dd",
   "metadata": {},
   "source": [
    "This code will generate the csv files that can be feeded to dnabert-2 method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b940bba7-ca47-4c15-b18c-5848e29b1902",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets have been split and saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training and temp sets\n",
    "train_df, temp_df = train_test_split(final_df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split temp set into testing and development sets\n",
    "test_df, dev_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Save the datasets to CSV files (optional)\n",
    "create_or_empty_directory(path_+\"/dnabert_2\")\n",
    "\n",
    "\n",
    "train_df.to_csv(f\"{path_}/dnabert_2/train.csv\", index=False)\n",
    "test_df.to_csv(f\"{path_}/dnabert_2/test.csv\", index=False)\n",
    "dev_df.to_csv(f\"{path_}/dnabert_2/dev.csv\", index=False)\n",
    "\n",
    "print(\"Datasets have been split and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ac4f50-863f-4a0d-8092-e4fea2f8e60f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Format the data for DExTER method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff937ff5-fccb-4484-b676-6f487d70e569",
   "metadata": {},
   "source": [
    "This code make sure that the split of data is the same with the one being used with grch37 (the data sent by dexter authors) you can eliminate this caracteristics easily "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75a3d6d6-761c-404a-950a-99e1f4ebaf37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les séquences ont été remplacées et enregistrées dans DATASETS/GRCH38/2000_tss_2000/dexter/dexter_grch38_genes.fa\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import os\n",
    "\n",
    "# Chargement du fichier CSV contenant les IDs et les séquences\n",
    "csv_file = 'DATASETS/GRCH38/2000_tss_2000/2000_tss_2000.csv'\n",
    "csv_data = pd.read_csv(csv_file)\n",
    "\n",
    "# Création d'un dictionnaire pour accéder facilement aux séquences par leur ID (avant le point)\n",
    "sequence_dict = {}\n",
    "for index, row in csv_data.iterrows():\n",
    "    seq_id = row['last_gene_id'].split('.')[0]\n",
    "    sequence_dict[seq_id] = row['centred_sequence']\n",
    "\n",
    "# Lecture du fichier FASTA envoyé par les auteurs de Dexter et remplacement des séquences \n",
    "fasta_file = 'send_by_dexter_guys/ncbiRefSeqCurated.hg19.2kb.around.geneStart.ENSEMBLgeneID.fa'\n",
    "fasta_records = list(SeqIO.parse(fasta_file, 'fasta'))\n",
    "\n",
    "# Liste pour stocker les nouveaux enregistrements FASTA\n",
    "new_fasta_records = []\n",
    "\n",
    "# Remplacement des séquences dans les enregistrements FASTA\n",
    "for record in fasta_records:\n",
    "    gene_id = record.id.split('.')[0]\n",
    "    if gene_id in sequence_dict:\n",
    "        new_seq = Seq(sequence_dict[gene_id])\n",
    "        new_record = SeqRecord(new_seq, id=record.id, description=record.description)\n",
    "        new_fasta_records.append(new_record)\n",
    "\n",
    "# Définir le chemin du fichier de sortie\n",
    "output_fasta_file = 'DATASETS/GRCH38/2000_tss_2000/dexter/dexter_grch38_genes.fa'\n",
    "\n",
    "# Créer le répertoire si nécessaire\n",
    "os.makedirs(os.path.dirname(output_fasta_file), exist_ok=True)\n",
    "\n",
    "# Écriture des enregistrements modifiés dans un nouveau fichier FASTA avec des séquences sur une seule ligne\n",
    "with open(output_fasta_file, 'w') as output_handle:\n",
    "    for record in new_fasta_records:\n",
    "        output_handle.write(f\">{record.id}\\n\")\n",
    "        output_handle.write(str(record.seq) + \"\\n\")\n",
    "\n",
    "print(f\"Les séquences ont été remplacées et enregistrées dans {output_fasta_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30407f5-3dc6-46ec-87e2-f4499d46b391",
   "metadata": {},
   "source": [
    "now we have our sequences orgnised as the data sent by dexter authors we need the expression data for dexter method we have only to give the expression data over all the tissues and there are algorithms that gonna associate each sequence with its corresponding expression with the tissue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9edfefd-cc8f-4435-9422-372bcefec804",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DATASETS/GRCH38/2000_tss_2000/dexter/GTEx_gene_median_7tissues.tsv'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Chemins des fichiers source et destination\n",
    "\n",
    "source_file = 'send_by_dexter_guys/GTEx_gene_median_7tissues.tsv'\n",
    "destination_file = 'DATASETS/GRCH38/2000_tss_2000/dexter/GTEx_gene_median_7tissues.tsv'\n",
    "os.makedirs(os.path.dirname(destination_file), exist_ok=True)\n",
    "\n",
    "# Copier le fichier\n",
    "shutil.copy(source_file, destination_file)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
