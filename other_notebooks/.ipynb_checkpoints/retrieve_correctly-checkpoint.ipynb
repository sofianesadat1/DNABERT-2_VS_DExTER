{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82bc1def-93eb-427e-9642-8553963444c3",
   "metadata": {},
   "source": [
    "## change just here the sequence length that you want "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1c7830a-33f8-4ab2-8abd-56ce81c513db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NC_000001.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_7402/1252905593.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['centred_sequence'] = df_filtered.apply(get_centered_sequence, axis=1)\n",
      "/var/tmp/ipykernel_7402/1252905593.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['centred_sequence_'] = df_filtered.apply(lambda row: reverse_complement(row['centred_sequence'].upper()) if row['strand'] == '-' else row['centred_sequence'], axis=1)\n",
      "/var/tmp/ipykernel_7402/1252905593.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered.drop(columns = [\"centred_sequence\"], inplace = True)\n",
      "/var/tmp/ipykernel_7402/1252905593.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered.rename(columns = {\"centred_sequence_\" : \"centred_sequence\"}, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "sequence_length_left = 0\n",
    "sequence_length_right = 8750\n",
    "\n",
    "\n",
    "\n",
    "# Les deux listes\n",
    "liste_nc = [\n",
    "    'NC_000001.11', 'NC_000002.12', 'NC_000003.12', 'NC_000004.12', 'NC_000005.10',\n",
    "    'NC_000006.12', 'NC_000007.14', 'NC_000008.11', 'NC_000009.12',\n",
    "    'NC_000010.11', 'NC_000011.10', 'NC_000012.12', 'NC_000013.11',\n",
    "    'NC_000014.9', 'NC_000015.10', 'NC_000016.10', 'NC_000017.11',\n",
    "    'NC_000018.10', 'NC_000019.10', 'NC_000020.11', 'NC_000021.9',\n",
    "    'NC_000022.11', 'NC_000023.11', 'NC_000024.10'\n",
    "]\n",
    "\n",
    "liste_chr = [\n",
    "    'chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8',\n",
    "    'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16',\n",
    "    'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX',\n",
    "    'chrY'\n",
    "]\n",
    "\n",
    "# Création du dictionnaire dans l'ordre demandé\n",
    "dex_to_ncbi = dict(zip(liste_chr, liste_nc))\n",
    "\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "\n",
    "# Charger le fichier FASTA et stocker les séquences dans un dictionnaire\n",
    "fasta_file = \"../ncbi_dataset/data/GCF_000001405.40/GCF_000001405.40_GRCh38.p14_genomic.fna\"\n",
    "chromosome_sequences = {}\n",
    "for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "    chromosome_sequences[record.id] = str(record.seq)\n",
    "\n",
    "# Charger le DataFrame\n",
    "df = pd.read_csv(\"dex_annotations_important.csv\")\n",
    "df_filtered = df[df['seqname'] != 'chrM']\n",
    "\n",
    "# Définir la longueur de la séquence à extraire (par exemple, 5000 bases de chaque côté)\n",
    "\n",
    "# Fonction pour extraire la séquence centrée autour de 'start' ou 'end' basé sur 'strand'\n",
    "def get_centered_sequence(row):\n",
    "    chromosome = dex_to_ncbi[row['seqname']]\n",
    "    if row['strand'] == '+':\n",
    "        center = row['start']\n",
    "    else:\n",
    "        center = row['end']\n",
    "    \n",
    "    seq = chromosome_sequences.get(chromosome, \"\")\n",
    "    if seq:\n",
    "        start_idx = max(0, center - sequence_length_left)\n",
    "        end_idx = min(len(seq), center + sequence_length_right)\n",
    "        return seq[start_idx-1:end_idx]\n",
    "    return \"\"\n",
    "\n",
    "# Ajouter la nouvelle colonne avec les séquences extraites\n",
    "df_filtered['centred_sequence'] = df_filtered.apply(get_centered_sequence, axis=1)\n",
    "\n",
    "def reverse_complement(sequence):\n",
    "    # Dictionnaire de complémentarité des nucléotides\n",
    "    complement = {'A': 'T', 'T': 'A', 'C': 'G', 'G': 'C',\n",
    "                  'a': 't', 't': 'a', 'c': 'g', 'g': 'c',\n",
    "                  'N': 'N', 'n': 'n'}  # 'N' reste 'N', 'n' reste 'n'\n",
    "    \n",
    "    # Générer la séquence complémentaire\n",
    "    complement_sequence = ''.join(complement.get(base, base) for base in sequence)\n",
    "    \n",
    "    # Inverser la séquence complémentaire\n",
    "    reverse_complement_sequence = complement_sequence[::-1]\n",
    "    \n",
    "    return reverse_complement_sequence\n",
    "\n",
    "df_filtered['centred_sequence_'] = df_filtered.apply(lambda row: reverse_complement(row['centred_sequence'].upper()) if row['strand'] == '-' else row['centred_sequence'], axis=1)\n",
    "df_filtered.drop(columns = [\"centred_sequence\"], inplace = True)\n",
    "df_filtered.rename(columns = {\"centred_sequence_\" : \"centred_sequence\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1d23ac-7174-4de7-bc91-b9235b0ffbc8",
   "metadata": {},
   "source": [
    "## Function to create the directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae634c7f-2690-47c6-b50d-6a822e9ceb22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def create_or_empty_directory(dir_path):\n",
    "    if os.path.exists(dir_path):\n",
    "        # If directory exists, delete all its contents\n",
    "        shutil.rmtree(dir_path)\n",
    "    # Create the directory (or recreate it if it was deleted)\n",
    "    os.makedirs(dir_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e672a0b2-82d1-45d0-b278-0f4d4bbc8295",
   "metadata": {},
   "source": [
    "## Create the train test set similar as dexter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a91a9ea-cc57-403e-80ce-a1f2f998d0cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if sequence_length_left > 0 and sequence_length_right > 0:\n",
    "    path_ = f\"DNABERT_2/DATASETS/GRCH38/{sequence_length_left}_tss_{sequence_length_right}\"\n",
    "elif sequence_length_left > 0:\n",
    "    path_ = f\"DNABERT_2/DATASETS/GRCH38/{sequence_length_left}_tss\"\n",
    "elif sequence_length_right > 0:\n",
    "    path_ = f\"DNABERT_2/DATASETS/GRCH38/tss_{sequence_length_right}\"\n",
    "else:\n",
    "    path_ = \"DNABERT_2/DATASETS/GRCH38/tss\"\n",
    "create_or_empty_directory(path_)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the initial DataFrame\n",
    "pituitary = pd.read_csv(\"human_genes_expression_pit/created_by_me/final_result.csv\")\n",
    "final_df = pd.merge(df_filtered, pituitary, left_on=\"GENE_ID\", right_on='gene_id')\n",
    "\n",
    "# Replace zeros with a small value to avoid errors in log transformation\n",
    "final_df['Pituitary'] = final_df['Pituitary'].replace(0, 0.001)\n",
    "\n",
    "# Take the logarithm base 10 of the 'Pituitary' column\n",
    "final_df['Pituitary'] = np.log10(final_df['Pituitary'])\n",
    "\n",
    "# Select desired columns\n",
    "final_df = final_df[['centred_sequence', 'Pituitary', 'last_gene_id', 'GENE_ID', 'dex_gene_id']]\n",
    "\n",
    "# Convert 'centred_sequence' to uppercase\n",
    "final_df['centred_sequence'] = final_df['centred_sequence'].str.upper()\n",
    "\n",
    "# Load the training set data\n",
    "train_dex = pd.read_csv(\"DExTER/example/my_experience_human/training_set.log\", names=[\"gene_id_dex_version\"])\n",
    "\n",
    "# Merge with final_df to get training data with required columns\n",
    "data_train_dex = pd.merge(train_dex, final_df, how=\"left\", left_on=\"gene_id_dex_version\", right_on=\"dex_gene_id\")\n",
    "\n",
    "# Select specific columns for training data\n",
    "data_train_dex = data_train_dex[['centred_sequence', 'Pituitary', 'last_gene_id']]\n",
    "\n",
    "# Remove rows with NaN values (if any)\n",
    "data_train_dex = data_train_dex.dropna()\n",
    "\n",
    "# Splitting into train (87%) and dev (13%)\n",
    "train_df, dev_df = train_test_split(data_train_dex, test_size=0.13, random_state=42)\n",
    "\n",
    "\n",
    "# Save train and dev datasets to CSV files\n",
    "train_df.to_csv(path_ + \"/train.csv\", index=False)\n",
    "dev_df.to_csv(path_ + \"/dev.csv\", index=False)\n",
    "\n",
    "# Load the testing set data\n",
    "test_dex = pd.read_csv(\"DExTER/example/my_experience_human/testing_set.log\", names=[\"gene_id_dex_version\"])\n",
    "\n",
    "# Merge with final_df to get testing data with required columns\n",
    "data_test_dex = pd.merge(test_dex, final_df, how=\"left\", left_on=\"gene_id_dex_version\", right_on=\"dex_gene_id\")\n",
    "\n",
    "# Select specific columns for testing data\n",
    "data_test_dex = data_test_dex[['centred_sequence', 'Pituitary', 'last_gene_id']]\n",
    "\n",
    "# Remove rows with NaN values (if any)\n",
    "data_test_dex = data_test_dex.dropna()\n",
    "\n",
    "# Save testing dataset to a CSV file\n",
    "data_test_dex.to_csv(path_ + \"/test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb61310e-0c63-4f4c-b618-f1f0171831e6",
   "metadata": {},
   "source": [
    "## datasets with differents seeds as dexter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93f6e1b2-b42c-4350-b9d6-4115794893e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#modify here the path where you want your files \n",
    "path_ = \"DNABERT_2/DATASETS/GRCH38/2000tss2000_seed4\"\n",
    "\n",
    "final_df = pd.read_csv(\"DNABERT_2/DATASETS/GRCH38/2000tss2000/2000_tss_2000.csv\")\n",
    "\n",
    "#modify here the dexter files \n",
    "train_dex = pd.read_csv(\"DExTER/example/grch38_SEED4/training_set.log\", names=[\"gene_id_dex_version\"])\n",
    "test_dex = pd.read_csv(\"DExTER/example/grch38_SEED4/testing_set.log\", names=[\"gene_id_dex_version\"])\n",
    "\n",
    "# Remove version numbers from 'gene_id' columns\n",
    "final_df['gene_id_stripped'] = final_df['last_gene_id'].apply(lambda x: x.split('.')[0])\n",
    "train_dex['gene_id_stripped'] = train_dex['gene_id_dex_version'].apply(lambda x: x.split('.')[0])\n",
    "test_dex['gene_id_stripped'] = test_dex['gene_id_dex_version'].apply(lambda x: x.split('.')[0])\n",
    "\n",
    "\n",
    "\n",
    "create_or_empty_directory(path_)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Merge with final_df to get training data with required columns\n",
    "data_train_dex = pd.merge(train_dex, final_df, how=\"left\", left_on=\"gene_id_stripped\", right_on=\"gene_id_stripped\")\n",
    "\n",
    "# Select specific columns for training data\n",
    "data_train_dex = data_train_dex[['centred_sequence', 'Pituitary', 'last_gene_id']]\n",
    "\n",
    "# Remove rows with NaN values (if any)\n",
    "data_train_dex = data_train_dex.dropna()\n",
    "\n",
    "# Splitting into train (87%) and dev (13%)\n",
    "train_df, dev_df = train_test_split(data_train_dex, test_size=0.13, random_state=42)\n",
    "\n",
    "\n",
    "# Save train and dev datasets to CSV files\n",
    "train_df.to_csv(path_ + \"/train.csv\", index=False)\n",
    "dev_df.to_csv(path_ + \"/dev.csv\", index=False)\n",
    "\n",
    "\n",
    "# Merge with final_df to get testing data with required columns\n",
    "data_test_dex = pd.merge(test_dex, final_df, how=\"left\", left_on=\"gene_id_stripped\", right_on=\"gene_id_stripped\")\n",
    "\n",
    "# Select specific columns for testing data\n",
    "data_test_dex = data_test_dex[['centred_sequence', 'Pituitary', 'last_gene_id']]\n",
    "\n",
    "# Remove rows with NaN values (if any)\n",
    "data_test_dex = data_test_dex.dropna()\n",
    "\n",
    "# Save testing dataset to a CSV file\n",
    "data_test_dex.to_csv(path_ + \"/test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941f9660-0acf-4d7d-a01f-af85f1a9742b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
